{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModernBERT is a robust and versatile language model designed for natural language understanding tasks. It leverages the power of transformer architecture to provide state-of-the-art performance in various NLP applications. In this notebook, we will demonstrate several tasks that can be performed using the ModernBERT model, including masked language modeling, feature extraction, sentence similarity, and next-word prediction. These tasks will showcase the capabilities of ModernBERT without requiring any fine-tuning, highlighting its effectiveness in handling diverse language processing challenges right out of the box.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install skikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Language Modeling (Fill-Mask Task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Text: The capital of France is [MASK].\n",
      "Predictions:\n",
      "  - The capital of France is Paris. (score: 0.9233)\n",
      "  - The capital of France is Lyon. (score: 0.0359)\n",
      "  - The capital of France is Nancy. (score: 0.0231)\n",
      "  - The capital of France is Nice. (score: 0.0062)\n",
      "  - The capital of France is Orleans. (score: 0.0026)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the fill-mask pipeline\n",
    "fill_mask = pipeline(\n",
    "    task=\"fill-mask\",\n",
    "    model=\"answerdotai/ModernBERT-base\",\n",
    "    tokenizer=\"answerdotai/ModernBERT-base\",\n",
    ")\n",
    "\n",
    "# Example masked text\n",
    "masked_text = \"The capital of France is [MASK].\"\n",
    "\n",
    "# Get predictions for the masked token\n",
    "predictions = fill_mask(masked_text)\n",
    "\n",
    "# Display predictions\n",
    "print(\"Masked Text:\", masked_text)\n",
    "print(\"Predictions:\")\n",
    "for pred in predictions:\n",
    "    print(f\"  - {pred['sequence']} (score: {pred['score']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted feature shape: 1 x 14\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the feature extraction pipeline\n",
    "feature_extractor = pipeline(\n",
    "    task=\"feature-extraction\",\n",
    "    model=\"answerdotai/ModernBERT-base\",\n",
    "    tokenizer=\"answerdotai/ModernBERT-base\",\n",
    ")\n",
    "\n",
    "# Example text\n",
    "text = \"ModernBERT is a robust model for natural language understanding.\"\n",
    "\n",
    "# Extract features\n",
    "features = feature_extractor(text)\n",
    "\n",
    "# Display feature dimensions\n",
    "print(f\"Extracted feature shape: {len(features)} x {len(features[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between sentences: 0.9572\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize the feature extraction pipeline\n",
    "feature_extractor = pipeline(\n",
    "    task=\"feature-extraction\",\n",
    "    model=\"answerdotai/ModernBERT-base\",\n",
    "    tokenizer=\"answerdotai/ModernBERT-base\",\n",
    ")\n",
    "\n",
    "# Example sentences\n",
    "sentence_1 = \"ModernBERT is a great language model.\"\n",
    "sentence_2 = \"ModernBERT excels in understanding language.\"\n",
    "\n",
    "# Extract embeddings\n",
    "embedding_1 = feature_extractor(sentence_1)[0][0]\n",
    "embedding_2 = feature_extractor(sentence_2)[0][0]\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity = cosine_similarity([embedding_1], [embedding_2])\n",
    "print(f\"Similarity between sentences: {similarity[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next-Word Prediction (Using Fill-Mask for Continuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Text: ModernBERT is designed for [MASK].\n",
      "Next Word Predictions:\n",
      "  - ModernBERT is designed for you. (score: 0.1343)\n",
      "  - ModernBERT is designed for men. (score: 0.0817)\n",
      "  - ModernBERT is designed for women. (score: 0.0586)\n",
      "  - ModernBERT is designed for professionals. (score: 0.0557)\n",
      "  - ModernBERT is designed for adults. (score: 0.0540)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the fill-mask pipeline\n",
    "fill_mask = pipeline(\n",
    "    task=\"fill-mask\",\n",
    "    model=\"answerdotai/ModernBERT-base\",\n",
    "    tokenizer=\"answerdotai/ModernBERT-base\",\n",
    ")\n",
    "\n",
    "# Example text with a masked token at the end\n",
    "masked_text = \"ModernBERT is designed for [MASK].\"\n",
    "\n",
    "# Get predictions\n",
    "predictions = fill_mask(masked_text)\n",
    "\n",
    "# Display next-word predictions\n",
    "print(\"Masked Text:\", masked_text)\n",
    "print(\"Next Word Predictions:\")\n",
    "for pred in predictions:\n",
    "    print(f\"  - {pred['sequence']} (score: {pred['score']:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
